#!/usr/bin/env python3
"""
Bulk downloader historickÃ½ch dat pro top 100 ETF z Yahoo Finance
Data uklÃ¡dÃ¡ lokÃ¡lnÄ› do CSV souborÅ¯ pro testovÃ¡nÃ­ kvality
"""

import yfinance as yf
import pandas as pd
import json
import os
import time
from datetime import datetime, timedelta
import logging

# NastavenÃ­ loggingu
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def load_etf_list():
    """NaÄte seznam top 100 ETF"""
    filename = "/Users/tomaskostrhoun/Documents/ETF/top100_etf_for_yahoo_test.json"
    
    with open(filename, 'r', encoding='utf-8') as f:
        etfs = json.load(f)
    
    logger.info(f"ğŸ“‹ NaÄten seznam {len(etfs)} ETF pro testovÃ¡nÃ­")
    return etfs

def download_etf_data(ticker, period="2y", retries=3):
    """StÃ¡hne historickÃ¡ data pro jeden ETF"""
    
    for attempt in range(retries):
        try:
            etf = yf.Ticker(ticker)
            
            # HistorickÃ¡ data (OHLCV)
            hist = etf.history(period=period)
            
            # Info data (zÃ¡kladnÃ­ informace)
            info = etf.info
            
            # Dividendy
            dividends = etf.dividends
            
            # Stock splits
            splits = etf.splits
            
            result = {
                'ticker': ticker,
                'success': True,
                'data_available': len(hist) > 0,
                'days_count': len(hist),
                'start_date': hist.index[0].strftime('%Y-%m-%d') if len(hist) > 0 else None,
                'end_date': hist.index[-1].strftime('%Y-%m-%d') if len(hist) > 0 else None,
                'has_dividends': len(dividends) > 0,
                'dividend_count': len(dividends),
                'has_splits': len(splits) > 0,
                'historical_data': hist,
                'dividends': dividends,
                'splits': splits,
                'info': info,
                'download_timestamp': datetime.now().isoformat()
            }
            
            # ZÃ¡kladnÃ­ metriky z info
            if info:
                result.update({
                    'current_price': info.get('regularMarketPrice'),
                    'market_cap': info.get('marketCap'),
                    'volume': info.get('volume'),
                    'currency': info.get('currency'),
                    'exchange': info.get('exchange'),
                    'fund_family': info.get('fundFamily'),
                    'expense_ratio': info.get('annualReportExpenseRatio') or info.get('netExpenseRatio'),
                    'nav_price': info.get('navPrice'),
                    'total_assets': info.get('totalAssets'),
                    'ytd_return': info.get('ytdReturn'),
                    'beta': info.get('beta'),
                    'yield': info.get('yield')
                })
            
            logger.info(f"âœ… {ticker:>8} | {len(hist):>4} dnÃ­ | {info.get('shortName', 'N/A')[:30]:30}")
            return result
            
        except Exception as e:
            if attempt < retries - 1:
                logger.warning(f"âš ï¸  {ticker:>8} | Pokus {attempt + 1} neÃºspÄ›Å¡nÃ½: {e}")
                time.sleep(2)  # Pauza pÅ™ed dalÅ¡Ã­m pokusem
            else:
                logger.error(f"âŒ {ticker:>8} | Selhalo po {retries} pokusech: {e}")
                return {
                    'ticker': ticker,
                    'success': False,
                    'error': str(e),
                    'download_timestamp': datetime.now().isoformat()
                }
    
    return None

def save_etf_data(etf_data, output_dir):
    """UloÅ¾Ã­ data jednoho ETF do CSV souborÅ¯"""
    
    ticker = etf_data['ticker']
    
    # VyÄistÃ­me ticker pro nÃ¡zev souboru (nahradÃ­me teÄky a speciÃ¡lnÃ­ znaky)
    clean_ticker = ticker.replace('.', '_').replace('/', '_')
    
    # HlavnÃ­ historickÃ¡ data
    if etf_data.get('data_available') and not etf_data['historical_data'].empty:
        hist_file = os.path.join(output_dir, f"{clean_ticker}_historical.csv")
        etf_data['historical_data'].to_csv(hist_file)
    
    # Dividendy
    if etf_data.get('has_dividends') and not etf_data['dividends'].empty:
        div_file = os.path.join(output_dir, f"{clean_ticker}_dividends.csv")
        etf_data['dividends'].to_csv(div_file)
    
    # Stock splits
    if etf_data.get('has_splits') and not etf_data['splits'].empty:
        splits_file = os.path.join(output_dir, f"{clean_ticker}_splits.csv")
        etf_data['splits'].to_csv(splits_file)
    
    # Metadata
    metadata = {k: v for k, v in etf_data.items() 
                if k not in ['historical_data', 'dividends', 'splits', 'info']}
    
    # PÅ™idÃ¡me vybranÃ¡ pole z info
    if etf_data.get('info'):
        info = etf_data['info']
        metadata['info_summary'] = {
            'longName': info.get('longName'),
            'shortName': info.get('shortName'),
            'category': info.get('category'),
            'fundFamily': info.get('fundFamily'),
            'currency': info.get('currency'),
            'exchange': info.get('exchange'),
            'marketCap': info.get('marketCap'),
            'totalAssets': info.get('totalAssets'),
            'netExpenseRatio': info.get('netExpenseRatio'),
            'annualReportExpenseRatio': info.get('annualReportExpenseRatio'),
            'yield': info.get('yield'),
            'ytdReturn': info.get('ytdReturn'),
            'beta': info.get('beta'),
            'volume': info.get('volume'),
            'regularMarketPrice': info.get('regularMarketPrice'),
            'fiftyTwoWeekHigh': info.get('fiftyTwoWeekHigh'),
            'fiftyTwoWeekLow': info.get('fiftyTwoWeekLow')
        }
    
    metadata_file = os.path.join(output_dir, f"{clean_ticker}_metadata.json")
    with open(metadata_file, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, indent=2, default=str, ensure_ascii=False)

def create_summary_report(all_results, output_dir):
    """VytvoÅ™Ã­ souhrnnÃ½ report o staÅ¾enÃ½ch datech"""
    
    logger.info("ğŸ“Š VytvÃ¡Å™enÃ­ souhrnnÃ©ho reportu...")
    
    # ZÃ¡kladnÃ­ statistiky
    total_etfs = len(all_results)
    successful = [r for r in all_results if r.get('success')]
    failed = [r for r in all_results if not r.get('success')]
    with_data = [r for r in successful if r.get('data_available')]
    with_dividends = [r for r in successful if r.get('has_dividends')]
    with_splits = [r for r in successful if r.get('has_splits')]
    
    # AnalÃ½za dat
    if with_data:
        avg_days = sum(r['days_count'] for r in with_data) / len(with_data)
        min_days = min(r['days_count'] for r in with_data)
        max_days = max(r['days_count'] for r in with_data)
        
        oldest_date = min(r['start_date'] for r in with_data if r['start_date'])
        newest_date = max(r['end_date'] for r in with_data if r['end_date'])
    else:
        avg_days = min_days = max_days = 0
        oldest_date = newest_date = "N/A"
    
    # AnalÃ½za exchange
    exchanges = {}
    currencies = {}
    fund_families = {}
    
    for result in successful:
        if result.get('exchange'):
            exchanges[result['exchange']] = exchanges.get(result['exchange'], 0) + 1
        if result.get('currency'):
            currencies[result['currency']] = currencies.get(result['currency'], 0) + 1
        if result.get('fund_family'):
            fund_families[result['fund_family']] = fund_families.get(result['fund_family'], 0) + 1
    
    # SouhrnnÃ½ report
    summary = {
        'generation_time': datetime.now().isoformat(),
        'statistics': {
            'total_etfs_tested': total_etfs,
            'successful_downloads': len(successful),
            'failed_downloads': len(failed),
            'success_rate_percent': (len(successful) / total_etfs * 100) if total_etfs > 0 else 0,
            'etfs_with_historical_data': len(with_data),
            'etfs_with_dividends': len(with_dividends),
            'etfs_with_splits': len(with_splits)
        },
        'data_coverage': {
            'average_days': avg_days,
            'min_days': min_days,
            'max_days': max_days,
            'oldest_data_from': oldest_date,
            'newest_data_to': newest_date
        },
        'exchanges': dict(sorted(exchanges.items(), key=lambda x: x[1], reverse=True)),
        'currencies': dict(sorted(currencies.items(), key=lambda x: x[1], reverse=True)),
        'fund_families': dict(sorted(fund_families.items(), key=lambda x: x[1], reverse=True)),
        'failed_tickers': [r['ticker'] for r in failed],
        'detailed_results': all_results
    }
    
    # UloÅ¾enÃ­ reportu
    report_file = os.path.join(output_dir, "download_summary_report.json")
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, default=str, ensure_ascii=False)
    
    # CSV s pÅ™ehledem
    csv_data = []
    for result in all_results:
        csv_data.append({
            'ticker': result['ticker'],
            'success': result.get('success', False),
            'has_data': result.get('data_available', False),
            'days_count': result.get('days_count', 0),
            'start_date': result.get('start_date', ''),
            'end_date': result.get('end_date', ''),
            'has_dividends': result.get('has_dividends', False),
            'dividend_count': result.get('dividend_count', 0),
            'has_splits': result.get('has_splits', False),
            'currency': result.get('currency', ''),
            'exchange': result.get('exchange', ''),
            'fund_family': result.get('fund_family', ''),
            'current_price': result.get('current_price', ''),
            'expense_ratio': result.get('expense_ratio', ''),
            'error': result.get('error', '')
        })
    
    csv_file = os.path.join(output_dir, "download_summary.csv")
    pd.DataFrame(csv_data).to_csv(csv_file, index=False)
    
    logger.info(f"âœ… SouhrnnÃ½ report uloÅ¾en: {report_file}")
    logger.info(f"âœ… CSV pÅ™ehled uloÅ¾en: {csv_file}")
    
    return summary

def main():
    print("ğŸš€ BULK DOWNLOAD HISTORICKÃCH DAT PRO TOP 100 ETF")
    print("=" * 60)
    
    # VytvoÅ™enÃ­ output sloÅ¾ky
    output_dir = "/Users/tomaskostrhoun/Documents/ETF/yahoo_finance_test_data"
    os.makedirs(output_dir, exist_ok=True)
    logger.info(f"ğŸ“ Output sloÅ¾ka: {output_dir}")
    
    # NaÄtenÃ­ seznamu ETF
    etfs = load_etf_list()
    
    print(f"\nğŸ“Š PlÃ¡n stahovÃ¡nÃ­:")
    print(f"   ETF k testovÃ¡nÃ­: {len(etfs)}")
    print(f"   ObdobÃ­: 2 roky")
    print(f"   Odhad Äasu: ~{len(etfs) * 3 / 60:.0f} minut")
    print(f"   Rate limit: 1 request per 2 seconds")
    
    # Automaticky pokraÄujeme bez potvrzenÃ­ pro automatickÃ© spuÅ¡tÄ›nÃ­
    print(f"\nğŸš€ AutomatickÃ© spuÅ¡tÄ›nÃ­ - pokraÄuji se stahovÃ¡nÃ­m...")
    
    # StahovÃ¡nÃ­ dat
    print(f"\nğŸš€ ZahÃ¡jenÃ­ stahovÃ¡nÃ­...")
    print("=" * 60)
    
    all_results = []
    
    for i, etf in enumerate(etfs, 1):
        ticker = etf.get('yahoo_ticker')
        if not ticker:
            logger.warning(f"âš ï¸  PÅ™eskakuji ETF bez tickeru: {etf.get('name', 'Unknown')}")
            continue
        
        logger.info(f"ğŸ“¥ [{i:3d}/{len(etfs)}] StahovÃ¡nÃ­ {ticker}...")
        
        # StÃ¡hni data
        result = download_etf_data(ticker, period="2y")
        
        if result:
            all_results.append(result)
            
            # UloÅ¾ data pokud jsou dostupnÃ¡
            if result.get('success') and result.get('data_available'):
                save_etf_data(result, output_dir)
        
        # Rate limiting - pauza mezi requesty
        if i < len(etfs):  # Ne po poslednÃ­m
            time.sleep(2)
    
    # VytvoÅ™ souhrnnÃ½ report
    print(f"\nğŸ“Š VytvÃ¡Å™enÃ­ souhrnnÃ©ho reportu...")
    summary = create_summary_report(all_results, output_dir)
    
    # FinÃ¡lnÃ­ statistiky
    print(f"\nâœ… STAHOVÃNÃ DOKONÄŒENO")
    print("=" * 30)
    print(f"ğŸ“Š Celkem testovÃ¡no: {summary['statistics']['total_etfs_tested']}")
    print(f"âœ… ÃšspÄ›Å¡nÄ› staÅ¾eno: {summary['statistics']['successful_downloads']}")
    print(f"âŒ NeÃºspÄ›Å¡nÃ½ch: {summary['statistics']['failed_downloads']}")
    print(f"ğŸ“ˆ ÃšspÄ›Å¡nost: {summary['statistics']['success_rate_percent']:.1f}%")
    print(f"ğŸ“… S daty: {summary['statistics']['etfs_with_historical_data']}")
    print(f"ğŸ’° S dividendami: {summary['statistics']['etfs_with_dividends']}")
    print(f"ğŸ”„ Se splity: {summary['statistics']['etfs_with_splits']}")
    
    if summary['statistics']['etfs_with_historical_data'] > 0:
        print(f"\nğŸ“Š PokrytÃ­ dat:")
        print(f"   PrÅ¯mÄ›r dnÃ­: {summary['data_coverage']['average_days']:.0f}")
        print(f"   NejstarÅ¡Ã­ od: {summary['data_coverage']['oldest_data_from']}")
        print(f"   NejnovÄ›jÅ¡Ã­ do: {summary['data_coverage']['newest_data_to']}")
    
    print(f"\nğŸ’¾ VÅ¡echna data uloÅ¾ena v: {output_dir}")
    
    return all_results, summary

if __name__ == "__main__":
    main()